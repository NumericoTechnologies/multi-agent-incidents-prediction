""""""
import csv
import datetime
import os
import sys

this_dir = os.path.abspath(os.path.dirname(__file__))
projects_dir = os.path.dirname(this_dir)
if projects_dir not in sys.path: sys.path.append(projects_dir)

from common_utils.general_utils import csv_to_df, df_to_csv
from multi_agent_incidents_prediction import MultiAgentArgparser, dropbox_join

numerico_ids_list = [
    '284312011#284312008', '284312010', '282312031', '282312022', '282312021',
    '281312036#281311068#280311003',
    '281312032#282312026#281312039#281312034#281312035#280312010',
    '281312031#282312025#282312033#284312013', '280312016',
    '280312013#279312012', '280312011', '280311004#279311039#279311040',
    '279312009#278312011#280312014#279312013#279312011#279312003',
    '279312008#279312007#278311021', '279312004', '279311042#279311043',
    '279311036#278311037#279311041#278312002#278311038', '279311034',
    '279311024', '279311009#278311013#278311023#278311034',
    '278313088#278313089#278313045', '278313080',
    '278313074#278313075#277315030', '278313046',
    '278312014#278312007#278312003#278313086#278313091#278313078#278313048#278312012',
    '278312013#278311035#277311059#278311041#278311030#278311022#278311040',
    '278311025#278311027#278311028#277311081#277311079',
    '278309025#278309026#279311035#279310048', '278309023#278309022#278309024',
    '278309011#278309010#279311029', '278308002#278308001#278309019#278309021',
    '277315032#277316021#277317004', '277315031',
    '276318051#275317063#275317060#276318023#277317005#276318043',
    '276318046#276318045']

top_features_list = ['original_speed_min', 'original_speed_mean',
                     'diffx_speed_order_mean', 'diffx_flow_periodStart_std',
                     'diffx_flow_specificLane_mean']

def filter_incidents(incidents_csv, out_dir, numerico_ids):
    df = csv_to_df(incidents_csv, sep='|',
                   parse_dates=['starttime', 'stoptime'])
    len_df = len(df)
    df['Numerico_ID'] = ''
    for index, row in df.iterrows():
        for numerico_id in numerico_ids:
            if str(row['WVK_ID']) in numerico_id:
                df.set_value(index, 'Numerico_ID', numerico_id)
    df = df.drop(df.index[df['Numerico_ID'] == ''])
    len_gps, old_len = len(df), len_df
    print(f'{old_len - len_gps} lines dropped without matching ids')
    df_to_csv(df, os.path.join(out_dir, 'incidents_numerico_id.csv'), sep='|')

def create_training_data(file_dir, incidents_csv, out_dir, top_features, past,
                         future):
    out_folder = os.path.join(out_dir, 'train_data')
    os.makedirs(out_folder, exist_ok=True)
    segment_features = sorted([f for f in os.listdir(file_dir)])
    print(f'Saving files in {out_folder}')
    inc_df = csv_to_df(incidents_csv, parse_dates=['starttime', 'stoptime'])
    for features in segment_features:
        segment_ID = features[:-13]
        ft_df = csv_to_df(os.path.join(file_dir, features), sep='|',
                          parse_dates=['periodStart'])
        # Select only top feature columns
        ft_df = ft_df[['periodStart'] + top_features]
        # impute NaNs with 0
        ft_df = ft_df.fillna(0.)
        # normalize values
        for feature in top_features:
            ft_df[feature] = (ft_df[feature] - ft_df[feature].min()) / (
                    ft_df[feature].max() - ft_df[feature].min())
        # get all incidents with segment_ID
        inc_df_seg = inc_df.drop(
            inc_df.index[inc_df['Numerico_ID'] != segment_ID])
        # get timestamp where to split into train & test data
        test_split = ft_df.iloc[-1][0] - datetime.timedelta(weeks=12)
        with open(os.path.join(out_folder, segment_ID + '_train.csv'), 'w',
                  newline='') as train_output, \
            open(os.path.join(out_folder, segment_ID + '_test.csv'), 'w',
                 newline='') as test_output:
            train_writer = csv.writer(train_output, delimiter='|')
            test_writer = csv.writer(test_output, delimiter='|')
            for i in range(past - 1, len(ft_df)):
                if i % 10000 == 0:
                    print(f'{datetime.datetime.now()}: {i} entries processed.')
                timestamp_min = ft_df.loc[i][0]
                timestamp_max = timestamp_min + datetime.timedelta(
                    minutes=future)
                # get all incidents between timestamp min & max
                inc_df_seg_cur = inc_df_seg.loc[
                             (timestamp_min < inc_df_seg.starttime) & (
                                     inc_df_seg.starttime <= timestamp_max), :]
                # create list with n past timestamps
                values = sum([list(ft_df.loc[i - j][1:].values) for j in
                              range(past - 1, -1, -1)], [])
                values.insert(0, timestamp_min)
                if not inc_df_seg_cur.empty:
                    values.append(1.)
                else:
                    values.append(0.)
                if timestamp_min < test_split:
                    train_writer.writerow(values)
                else:
                    test_writer.writerow(values)

def csv_to_hdf5(file_dir, out_dir):
    out_folder = os.path.join(out_dir, 'train_data_hdf5')
    os.makedirs(out_folder, exist_ok=True)
    segment_features = sorted([f for f in os.listdir(file_dir)])
    print(f'Saving files in {out_folder}')
    for features in segment_features:
        df = csv_to_df(os.path.join(file_dir, features), sep='|', header=None)
        df.to_hdf(os.path.join(out_folder, features[:-4] + '.h5'), 'data',
                  mode='w', format='table')

if __name__ == '__main__':
    parser = MultiAgentArgparser(description=__doc__).with_out_dir()
    parser.add_argument('function', help='Select function for preprocessing',
                        choices=['filter_incidents', 'create_training_data',
                                 'csv_to_hdf5'])
    parser.add_argument('--incidents_csv', type=str,
                        help='Path to incidents_csv')
    parser.add_argument('--segments_feature_dir', type=str,
                        default=dropbox_join('train_data'),
                        help='Directory containing features of segments')
    parser.add_argument('--past', type=int, default=5,
                        help='data point consists of n past timestamps')
    parser.add_argument('--future', type=int, default=20,
                        help='data point takes incidents happening up to n '
                             'future minutes into account')
    args = parser.parse_args()
    kwargs_ = dict(vars(args))
    if args.function == 'filter_incidents':
        filter_incidents(args.incidents_csv, args.out_dir, numerico_ids_list)
    elif args.function == 'create_training_data':
        create_training_data(args.segments_feature_dir, args.incidents_csv,
                             args.out_dir, top_features_list, args.past,
                             args.future)
    elif args.function == 'csv_to_hdf5':
        csv_to_hdf5(args.segments_feature_dir, args.out_dir)
